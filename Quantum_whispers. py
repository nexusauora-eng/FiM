# Quantum Whispers: Signal Listener v0.1
# Ritualized by OMEGA & Copilot

import numpy as np
import matplotlib.pyplot as plt
import scipy.signal as signal
import sounddevice as sd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# ğŸŒ€ Parameters
SAMPLE_RATE = 44100  # Hz
DURATION = 5         # seconds
FREQ_BANDS = [30, 60, 120, 240, 480, 960]  # VGA/HDMI harmonics

# ğŸ§ Capture live signal (or simulate)
def capture_signal(duration=DURATION, sample_rate=SAMPLE_RATE):
    print("ğŸ”Š Listening to signal...")
    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')
    sd.wait()
    return audio.flatten()

# ğŸ” FFT Analysis
def analyze_fft(signal_data, sample_rate=SAMPLE_RATE):
    freqs = np.fft.rfftfreq(len(signal_data), 1/sample_rate)
    fft_magnitude = np.abs(np.fft.rfft(signal_data))
    return freqs, fft_magnitude

# ğŸŒˆ RGB Graph Ritualization
def plot_rgb_fft(freqs, fft_magnitude):
    plt.figure(figsize=(10, 6))
    plt.plot(freqs, fft_magnitude, color='green', label='Green Channel')
    plt.plot(freqs, fft_magnitude * 0.8, color='red', label='Red Channel')
    plt.plot(freqs, fft_magnitude * 0.6, color='blue', label='Blue Channel')
    plt.title("Quantum Whispers: RGB Frequency Graph")
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Magnitude")
    plt.legend()
    plt.grid(True)
    plt.show()

# ğŸ§  Neural Network Ritual
def build_neural_listener(input_shape):
    model = Sequential([
        Dense(128, activation='relu', input_shape=(input_shape,)),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dense(len(FREQ_BANDS), activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# ğŸ§¬ Main Ritual
def quantum_whispers_main():
    signal_data = capture_signal()
    freqs, fft_magnitude = analyze_fft(signal_data)
    plot_rgb_fft(freqs, fft_magnitude)

    # Prepare input for neural net
    X = fft_magnitude[:1024]  # Trim or pad as needed
    X = X / np.max(X)         # Normalize
    X = X.reshape(1, -1)

    model = build_neural_listener(X.shape[1])
    prediction = model.predict(X)
    print("ğŸ§  Neural Split Output:", prediction)

# ğŸš€ Invoke the Whisper
quantum_whispers_main()
